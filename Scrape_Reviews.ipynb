{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dani-fadli/google-maps-reviews-scraper/blob/main/Scrape_Reviews.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F54Zx4KRHMw5",
        "outputId": "19208bab-211d-461d-ba5a-2f16fce83bee"
      },
      "outputs": [],
      "source": [
        "# Step 1: Install Chrome and dependencies in Colab\n",
        "!apt-get update\n",
        "!apt-get install -y chromium-chromedriver\n",
        "!cp /usr/lib/chromium-browser/chromedriver /usr/bin\n",
        "\n",
        "# Step 2: Install Python dependencies\n",
        "!pip install selenium pandas --quiet\n",
        "\n",
        "# Step 3: Use this configuration in your script\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "\n",
        "chrome_options = Options()\n",
        "chrome_options.add_argument(\"--headless\")\n",
        "chrome_options.add_argument(\"--no-sandbox\")\n",
        "chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
        "chrome_options.binary_location = \"/usr/bin/chromium-browser\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "gNSUwxzCF_Bh",
        "outputId": "1f7f2c93-4007-4913-c3ed-d93731d384ab"
      },
      "outputs": [],
      "source": [
        "# Google Colab Notebook\n",
        "# Title: Scraping Google Maps Reviews for Sentiment Analysis Thesis\n",
        "# Author: dani-fadli\n",
        "# Description: Scrapes reviews and ratings from Google Maps for a list of waterfall tourism spots in Bandung Raya.\n",
        "# Output: CSV file per place, named with place and timestamp, containing 'rating' and 'review' columns.\n",
        "\n",
        "# --- Install Requirements ---\n",
        "!pip install selenium webdriver-manager pandas --quiet\n",
        "\n",
        "# --- Imports ---\n",
        "import time\n",
        "import pandas as pd\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from webdriver_manager.chrome import ChromeDriverManager\n",
        "from datetime import datetime\n",
        "import re\n",
        "\n",
        "# --- Helper Functions ---\n",
        "def get_place_name_from_url(url):\n",
        "    # Extract the place name from the Google Maps URL for filename\n",
        "    # e.g., https://www.google.com/maps/place/Air+Terjun+X/...\n",
        "    match = re.search(r'/place/([^/]+)', url)\n",
        "    if match:\n",
        "        return match.group(1).replace('+', '_')\n",
        "    else:\n",
        "        return 'unknown_place'\n",
        "\n",
        "def scrape_google_maps_reviews(place_url, max_wait=2):\n",
        "    # Set up Chrome options for headless operation in Colab\n",
        "    # chrome_options = Options()\n",
        "    # chrome_options.add_argument(\"--headless\")\n",
        "    # chrome_options.add_argument(\"--window-size=1920,1080\")\n",
        "    # chrome_options.add_argument(\"--disable-gpu\")\n",
        "    # chrome_options.add_argument(\"--no-sandbox\")\n",
        "    # chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
        "\n",
        "    # driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
        "    driver = webdriver.Chrome(options=chrome_options)\n",
        "    driver.get(place_url)\n",
        "    time.sleep(5)  # Let the page load\n",
        "\n",
        "    # Scroll to the reviews section (simulate click on 'All reviews' button if present)\n",
        "    try:\n",
        "        all_reviews_button = driver.find_element(By.XPATH, '//button[contains(@aria-label, \"Ulasan\")]')\n",
        "        all_reviews_button.click()\n",
        "        time.sleep(3)\n",
        "    except Exception:\n",
        "        pass  # Button not found, maybe already in reviews\n",
        "\n",
        "    # Wait for reviews container to load\n",
        "    time.sleep(3)\n",
        "\n",
        "    # Find the scrollable reviews container\n",
        "    try:\n",
        "        scrollable_div = driver.find_element(By.XPATH, '//div[@role=\"region\" and @tabindex=\"0\"]')\n",
        "    except Exception:\n",
        "        scrollable_div = driver.find_element(By.XPATH, '//div[contains(@class, \"m6QErb DxyBCb kA9KIf dS8AEf XiKgde \")]')\n",
        "        # scrollable_div = driver.find_element(By.XPATH, '//div[contains(@class, \"m6QErb WNBkOb XiKgde\")]')\n",
        "\n",
        "    # Auto-scroll loop\n",
        "    last_height = driver.execute_script(\"return arguments[0].scrollHeight\", scrollable_div)\n",
        "    print(f\"Last height: {last_height}\")\n",
        "    scroll_tries = 0\n",
        "    while True:\n",
        "        driver.execute_script(\"arguments[0].scrollTo(0, arguments[0].scrollHeight);\", scrollable_div)\n",
        "        time.sleep(max_wait)\n",
        "        new_height = driver.execute_script(\"return arguments[0].scrollHeight\", scrollable_div)\n",
        "        print(f\"New height: {new_height}\")\n",
        "\n",
        "        # Limit scrolling for debugging\n",
        "        # if new_height > 5000:\n",
        "        #     break\n",
        "\n",
        "        # Retry if the new height is equal to the last height\n",
        "        if new_height == last_height:\n",
        "            scroll_tries += 1\n",
        "            if scroll_tries > 4:\n",
        "                break\n",
        "        else:\n",
        "            last_height = new_height\n",
        "            scroll_tries = 0\n",
        "        print(f\"Scroll tries: {scroll_tries}\")\n",
        "\n",
        "    # Expand all truncated reviews\n",
        "    more_buttons = driver.find_elements(By.XPATH, '//button[contains(@aria-label, \"Lihat lainnya\")]')\n",
        "    for btn in more_buttons:\n",
        "        try:\n",
        "            driver.execute_script(\"arguments[0].click();\", btn)\n",
        "            time.sleep(0.1)\n",
        "        except Exception:\n",
        "            continue\n",
        "\n",
        "    # Extract reviews and ratings\n",
        "    reviews = []\n",
        "    ratings = []\n",
        "    # review_blocks = driver.find_elements(By.XPATH, '//div[@data-review-id]')\n",
        "    review_blocks = driver.find_elements(By.XPATH, '//div[contains(@class, \"jJc9Ad \")]')\n",
        "    for block in review_blocks:\n",
        "        try:\n",
        "            rating = block.find_element(By.XPATH, './/span[@role=\"img\"]').get_attribute(\"aria-label\")\n",
        "            rating_val = re.search(r'(\\d+)\\s+bintang', rating)\n",
        "\n",
        "            if rating_val:\n",
        "                rating_num = int(rating_val.group(1))\n",
        "            else:\n",
        "                rating_num = None\n",
        "        except Exception:\n",
        "            rating_num = None\n",
        "        try:\n",
        "            review_text = block.find_element(By.XPATH, './/span[contains(@class, \"wiI7pd\")]').text\n",
        "            # # Find all elements that could contain review text within the block\n",
        "            # review_text_elements = block.find_elements(By.XPATH, './/span[contains(@class, \"wiI7pd\")]')\n",
        "\n",
        "            # # Find the element with the longest text, assuming it's the full review\n",
        "            # longest_text = \"\"\n",
        "            # for element in review_text_elements:\n",
        "            #     current_text = element.text.strip()\n",
        "            #     if len(current_text) > len(longest_text):\n",
        "            #         longest_text = current_text\n",
        "\n",
        "            # review_text = longest_text\n",
        "        except Exception:\n",
        "            review_text = \"\"\n",
        "        print(f\"Review: {review_text}\")\n",
        "        if review_text.strip():  # Only keep reviews with text\n",
        "            reviews.append(review_text.strip())\n",
        "            ratings.append(rating_num)\n",
        "\n",
        "    driver.quit()\n",
        "    return pd.DataFrame({'rating': ratings, 'review': reviews})\n",
        "\n",
        "# --- Main Scraping Logic ---\n",
        "\n",
        "# List your Google Maps URLs here\n",
        "place_urls = [\n",
        "    # \"https://www.google.com/maps/place/NAME1/...\",\n",
        "    # \"https://www.google.com/maps/place/NAME2/...\",\n",
        "    # ...\n",
        "    \"https://www.google.com/maps/place/Curug+Layung+%26+Camping+Ground/@-6.7770315,107.5799823,15z/data=!4m18!1m9!3m8!1s0x2e68e142f2d3bf0d:0x5765d9ceb0f35ae7!2sCurug+Layung+%26+Camping+Ground!8m2!3d-6.7768125!4d107.5778125!9m1!1b1!16s%2Fg%2F11hs54sggh!3m7!1s0x2e68e142f2d3bf0d:0x5765d9ceb0f35ae7!8m2!3d-6.7768125!4d107.5778125!9m1!1b1!16s%2Fg%2F11hs54sggh?hl=id&entry=ttu\"\n",
        "]\n",
        "\n",
        "for url in place_urls:\n",
        "    print(f\"Processing: {url}\")\n",
        "    place_name = get_place_name_from_url(url)\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    df = scrape_google_maps_reviews(url)\n",
        "    filename = f\"{place_name}_reviews_{timestamp}.csv\"\n",
        "    df.to_csv(filename, index=False)\n",
        "    print(f\"Saved: {filename}\")\n",
        "\n",
        "print(\"DONE. Check the files in your Colab workspace.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPorDomMnI+/sPGAlYlDulj",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
